# Archi - Copy to .env and fill in

# Context window size (tokens)
# Qwen3-VL supports 256K, but larger = more VRAM
# 32K = good balance for 8GB VRAM (default)
# 16K = conservative for 6GB VRAM
# 8K = safe for 4GB VRAM
# ARCHI_CONTEXT_SIZE=32768

# Local model (Gate B/C) - path to Qwen3VL GGUF (vision + reasoning)
# Place Qwen3VL-8B-Instruct-Q4_K_M.gguf + mmproj-Qwen3VL-8B-Instruct-F16.gguf in models/
# Requires JamePeng llama-cpp-python 0.3.24 fork for vision. See README.md.
# LOCAL_MODEL_PATH=C:/Archi/models/Qwen3VL-8B-Instruct-Q4_K_M.gguf
LOCAL_MODEL_PATH=

# Optional: CUDA toolkit root (for GPU build of llama-cpp-python)
# CUDA_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v13.1

# Optional: base path for logs, data, workspace (default: repo root)
# ARCHI_ROOT=C:/Archi

# === OpenRouter API (replaces direct Grok) ===
# 1. Create account at https://openrouter.ai
# 2. (Optional) Add your xAI key in Settings for BYOK (first 1M requests/month free)
# 3. Generate API key at https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-replace-with-your-key
# Model to use (provider/name format). Examples:
#   x-ai/grok-4.1-fast          — same as before (via BYOK = free routing)
#   deepseek/deepseek-chat-v3-0324  — excellent coder, very cheap
#   openrouter/auto              — auto-selects best model per prompt
OPENROUTER_MODEL=openrouter/auto
# Optional: separate vision model (defaults to OPENROUTER_MODEL)
# OPENROUTER_VISION_MODEL=openrouter/auto
# Optional: app attribution headers for OpenRouter leaderboards
# OPENROUTER_APP_REFERER=https://github.com/archi-agent
# OPENROUTER_APP_TITLE=Archi

# Legacy (deprecated) — migrate to OpenRouter above
# GROK_API_KEY=gsk_replace_with_your_key

# ANTHROPIC_API_KEY=
# GOOGLE_API_KEY=

# Gate C – Computer Use (optional)
# START_BUTTON_X=843           # px or fraction (e.g. 0.33)
# SKIP_API_VISION=1            # Disable API vision fallback
# DEBUG_CLICK=1                # Save annotated screenshot

# Discord bot (Gate G) - https://discord.com/developers/applications
# DISCORD_BOT_TOKEN=your_bot_token

# Limits
# DAILY_BUDGET_USD=5.00
# LOG_LEVEL=INFO

# Prefer local model (reduce API usage)
# ARCHI_PREFER_LOCAL_STRICT=1     # Never escalate to API when prefer_local=True
# ARCHI_CONVERSATIONAL_WORD_LIMIT=25   # Max user words for conversational threshold (default 25)
